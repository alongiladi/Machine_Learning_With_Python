{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alongiladi/Machine_Learning_With_Python/blob/main/group_7_excercise_4_Final_Exc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umhRfUQTiguc"
      },
      "source": [
        "## Assignment: Approve or Decline Loans\n",
        "\n",
        "In this assignment, we will use a dataset of loan applications to predict whether a loan should be approved or declined.\n",
        "Your task is to build a model that can predict the outcome of a loan application based on the given features.\n",
        "\n",
        "### Dataset\n",
        "- **Source:** https://raw.githubusercontent.com/schauppi/Intro_ML/main/datasets/loan_data.csv\n",
        "\n",
        "### Steps:\n",
        "\n",
        "1. **Explore the Data with Pandas**\n",
        "    - Load the data\n",
        "    - Display the first few rows of the data\n",
        "    - Check for missing values\n",
        "    - Get basic information about the data\n",
        "    - Convert categorical variables to numerical (Because we want to use a machine learning algorithm and they require numerical input)\n",
        "    - Get basic descriptive statistics\n",
        "2. **Data Visualization**\n",
        "    - Use Matplotlib to create visualizations to understand the data and spot potential patterns\n",
        "    - Plot the following:\n",
        "        - Distribution of person age\n",
        "        - Gender distribution\n",
        "        - Loan status proportion\n",
        "        - Loan amount vs. income\n",
        "3. **Prepare the Data for Modeling**\n",
        "    - Get the target and features\n",
        "    - Scale the features using `MinMaxScaler`\n",
        "    - Split the data into training and testing sets\n",
        "4. **Modeling**\n",
        "    - Train and evaluate an `SVM` with a `linear` kernel\n",
        "    - Train and evaluate an `SVM` with a `RBF` kernel\n",
        "    - Train and evaluate a `SVM` with a `polynomial` kernel\n",
        "5. **Grid Search**\n",
        "    - Use `GridSearchCV` to find the best hyperparameters for the `SVM` with a `RBF` kernel\n",
        "    - Set the parameters to search over:\n",
        "        - `C`: 0.1, 0.5, 1, 5, 10\n",
        "        - `kernel`: 'rbf'\n",
        "    - Set the number of cross-validation folds to 2\n",
        "    - Set the scoring metric to `f1`\n",
        "6. **Train and Evaluate the Model with the Best Hyperparameters**\n",
        "    - Train the `SVM` with the best hyperparameters found by `GridSearchCV`\n",
        "    - Evaluate the model on the testing set\n",
        "    - Print the accuracy, precision, recall, and F1 score of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsDbvbjhigud"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpKvc070igue"
      },
      "source": [
        "### 1. Explore the Data with Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VItaA8e5iguf"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/schauppi/Intro_ML/main/datasets/loan_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92xLYsyYiguf"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAiULpN7iguf"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-LXKI1Bigug"
      },
      "outputs": [],
      "source": [
        "# Get basic information about the data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGu_zDQ4igug"
      },
      "source": [
        "#### Data Conversion\n",
        "\n",
        "We are converting **categorical** (text-based) variables into **numerical values** using **label encoding**. This is necessary because **machine learning algorithms** can only process numerical data.\n",
        "\n",
        "**Conversions**:\n",
        " - **Gender**: female (0), male (1)\n",
        " - **Education**: High School (0), Bachelor (1), Master (2), Associate (3), Doctorate (4)\n",
        " - **Home Ownership**: MORTGAGE (0), RENT (1), OWN (2), OTHER (3)\n",
        " - **Loan Intent**: PERSONAL (0), EDUCATION (1), MEDICAL (2), VENTURE (3), HOMEIMPROVEMENT (4), DEBTCONSOLIDATION (5)\n",
        " - **Previous Defaults**: No (0), Yes (1)\n",
        "\n",
        "Using Pandas' `map()` function, we assign numerical values to each category. This allows our data to be processed by **machine learning algorithms** while maintaining the distinct categories in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41WbUDBDiguh"
      },
      "outputs": [],
      "source": [
        "# Convert categorical variables to numerical\n",
        "data['person_gender']=data['person_gender'].map({\"female\":0 ,\"male\":1})\n",
        "data['person_education']=data['person_education'].map({\"High School\":0 ,\"Bachelor\":1 , 'Master':2 , 'Associate':3 , 'Doctorate':4})\n",
        "data['person_home_ownership']=data['person_home_ownership'].map({\"MORTGAGE\":0 ,\"RENT\":1 , 'OWN':2 , 'OTHER':3})\n",
        "data['loan_intent']=data['loan_intent'].map({\"PERSONAL\":0 ,\"EDUCATION\":1 , 'MEDICAL':2 , 'VENTURE':3 , 'HOMEIMPROVEMENT':4 , 'DEBTCONSOLIDATION':5})\n",
        "data['previous_loan_defaults_on_file']=data['previous_loan_defaults_on_file'].map({\"No\":0 ,\"Yes\":1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnjZr4Cpiguh"
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the data and check if the conversion was successful\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvFWP2kmiguh"
      },
      "outputs": [],
      "source": [
        "# Get basic descriptive statistics\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZAWpP6Oiguh"
      },
      "source": [
        "### 2. Data Visualization\n",
        "\n",
        "You will visualize the distribution of **person age**, **gender distribution**, **loan status proportion**, and the relationship between **loan amount and income** to better understand our dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjWFnQ3rigui"
      },
      "outputs": [],
      "source": [
        "# Plot distribution for 'person_age'\n",
        "data['person_age'].plot(kind='hist')\n",
        "plt.title(\"Distribution of Person Age\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ2RSnSsiguj"
      },
      "source": [
        "Create a bar plot showing gender distribution in the dataset using `value_counts()` with blue for female (0) and pink for male (1) to visualize gender balance in loan applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_656SZliguj"
      },
      "outputs": [],
      "source": [
        "# Plot gender distribution\n",
        "data['person_gender'].value_counts().plot(kind='bar', color=['blue', 'pink'])\n",
        "plt.title(\"Gender Distribution\")\n",
        "plt.xlabel(\"Gender (0=Female, 1=Male)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhKzJFQPiguj"
      },
      "source": [
        "Create a pie chart visualizing loan status proportion using `value_counts()` with autopct to display percentages, helping you understand the balance between approved and declined loans.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMhtG7Ldiguj"
      },
      "outputs": [],
      "source": [
        "# Plot loan status proportion\n",
        "data['loan_status'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.title(\"Loan Status Proportion\")\n",
        "plt.ylabel(\"\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9TBqCGFiguj"
      },
      "source": [
        "Create a scatter plot visualizing the relationship between loan amount and person income, which helps identify patterns and potential correlations in loan applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqM2AXECiguj"
      },
      "outputs": [],
      "source": [
        "# Plot loan amount vs. income\n",
        "plt.scatter(data['person_income'], data['loan_amnt'], alpha=0.5)\n",
        "plt.title(\"Loan Amount vs. Income\")\n",
        "plt.xlabel(\"Income\")\n",
        "plt.ylabel(\"Loan Amount\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85JgkTD_iguk"
      },
      "source": [
        "### 3. Prepare the Data for Modeling\n",
        "\n",
        "Split the data into features (X) and target (y), scale the features using MinMaxScaler, then divide into training and testing sets with an 80-20 split and random_state=42 for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBBejXpHiguk"
      },
      "outputs": [],
      "source": [
        "# Get the target and features\n",
        "X = data.drop('loan_status', axis=1)\n",
        "y = data['loan_status']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xq43Ahtigue"
      },
      "outputs": [],
      "source": [
        "# Scale the features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjsSy-xRigul"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic1sOX3Xigul"
      },
      "source": [
        "### 4. Modeling\n",
        "\n",
        "Train and evaluate three SVM models with different kernels (linear, RBF, polynomial), then assess their performance using accuracy, precision, recall, and F1 score metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIIpxzNPigul"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate an SVM with a linear kernel\n",
        "svm_linear = SVC(kernel='linear', C=1)\n",
        "svm_linear.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEjuHWU9igul"
      },
      "outputs": [],
      "source": [
        "# get predictions\n",
        "y_pred = svm_linear.predict(X_test)\n",
        "\n",
        "# evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz5j7w5Zigul"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate an SVM with a RBF kernel\n",
        "svm_rbf = SVC(kernel='rbf', C=1)\n",
        "svm_rbf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmHKvMgQigum"
      },
      "outputs": [],
      "source": [
        "# get predictions\n",
        "y_pred = svm_rbf.predict(X_test)\n",
        "\n",
        "# evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjcXkP0zigum"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate an SVM with a polynomial kernel\n",
        "svm_poly = SVC(kernel='poly', C=1)\n",
        "svm_poly.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TZKHJFgigum"
      },
      "outputs": [],
      "source": [
        "# get predictions\n",
        "y_pred = svm_poly.predict(X_test)\n",
        "\n",
        "# evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YDeOYV0igum"
      },
      "source": [
        "### 5. Grid Search\n",
        "\n",
        "You will use `GridSearchCV` to find the best hyperparameters for the `SVM` with a `RBF` kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4dw7Duvigum"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 0.5, 1, 5, 10],\n",
        "    'kernel': ['rbf']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUxFhzMMigun"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate an SVM with a RBF kernel using GridSearchCV\n",
        "svm_rbf_gs = SVC()\n",
        "grid_search = GridSearchCV(svm_rbf_gs, param_grid, cv=2, scoring='f1')\n",
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GneY0UWqigun"
      },
      "outputs": [],
      "source": [
        "# Print the best parameters and the best score\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr8aaEGGigun"
      },
      "source": [
        "### 6. Train and Evaluate the Model with the Best Hyperparameters\n",
        "\n",
        "Here you will train the `SVM` with the best hyperparameters found by `GridSearchCV` and evaluate it on the testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEpmu_taigun"
      },
      "outputs": [],
      "source": [
        "# Train the SVM with the best hyperparameters found by GridSearchCV\n",
        "svm_rbf_best = SVC(kernel='rbf', C=grid_search.best_params_['C'])\n",
        "svm_rbf_best.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8diuUKJigun"
      },
      "outputs": [],
      "source": [
        "# get predictions\n",
        "y_pred = svm_rbf_best.predict(X_test)\n",
        "\n",
        "# evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 score:\", f1_score(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "karli_pd",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}